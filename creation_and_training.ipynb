{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In diesem File werden die Modelle erstellt, trainiert und die Experimente durchgef√ºhrt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports, Variablen & Definitionen von Funktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "import foolbox as fb\n",
    "from keras import callbacks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from itertools import product\n",
    "from scipy.ndimage.interpolation import rotate, shift\n",
    "import csv\n",
    "\n",
    "\n",
    "# variables\n",
    "epsilon=0.3\n",
    "batch_size=1024\n",
    "epochs=1000\n",
    "pgd_steps=50\n",
    "batch_count=0\n",
    "batch_count_inv=0\n",
    "print(\"Tensorflow version: \", tf.__version__)\n",
    "print(\"Numpy version: \", np.__version__)\n",
    "print(\"Foolbox version: \", fb.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "np.random.seed(10)\n",
    "\n",
    "\n",
    "# get MNIST data and prepare\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "img_rows = img_cols = 28\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# define variables needed for attacks\n",
    "x_attack_to_train = tf.convert_to_tensor(x_train, dtype=tf.float32)\n",
    "x_attack_to_train=x_attack_to_train[:,:,:,np.newaxis]\n",
    "y_attack_to_train=tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
    "\n",
    "x_attack_to_test = tf.convert_to_tensor(x_test, dtype=tf.float32)\n",
    "x_attack_to_test=x_attack_to_test[:,:,:,np.newaxis]\n",
    "y_attack_to_test=tf.convert_to_tensor(y_test, dtype=tf.int32)\n",
    "\n",
    "attack = fb.attacks.projected_gradient_descent.LinfProjectedGradientDescentAttack(steps=pgd_steps)\n",
    "\n",
    "# for generating invariance-based adversarial examples\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "# functions\n",
    "def test_model(model):\n",
    "    \n",
    "    assert epsilon==0.3\n",
    "    inv_advs_to_test=np.load(\"data/invariance_examples_tramer/linf/automated_eps03.npy\")[0:100]\n",
    "    inv_labels_to_test=np.load(\"data/invariance_examples_tramer/linf/automated_eps03_labels.npy\")[0:100]\n",
    "    fmodel=fb.models.tensorflow.TensorFlowModel(model, bounds=(0,1))      \n",
    "    \n",
    "    x_batch,y_batch=x_test[0:100],y_test[0:100]\n",
    "    x_batch_to_test = tf.convert_to_tensor(x_batch, dtype=tf.float32)\n",
    "    y_batch_to_test=tf.convert_to_tensor(y_batch, dtype=tf.int32)\n",
    "\n",
    "    _,advs_to_test, success=attack(fmodel,x_batch_to_test, y_batch_to_test, epsilons=epsilon)\n",
    "   \n",
    "    success_rate=tf.keras.backend.get_value(success).mean(axis=-1).round(2)\n",
    "    x=tf.keras.backend.get_value(advs_to_test)\n",
    "    ptb_test=x\n",
    "\n",
    "    # get accuracies and losses\n",
    "    acc =model.evaluate(x_test[0:100],to_categorical(y_test[0:100]), verbose=0)\n",
    "    acc_ptb = model.evaluate(ptb_test,to_categorical(y_batch), verbose=0)\n",
    "    acc_inv = model.evaluate(inv_advs_to_test,to_categorical(inv_labels_to_test), verbose=0)\n",
    "\n",
    "\n",
    "    # get invariance adversarial examples success rate\n",
    "    predictions=model.predict(inv_advs_to_test)\n",
    "    disagreeing=0\n",
    "    for i in range(len(predictions)):\n",
    "        if inv_labels_to_test[i] !=np.argmax(predictions[i]):\n",
    "            disagreeing+=1\n",
    "      \n",
    "    return {\n",
    "    \"clean\":{\"loss\": acc[0], \"accuracy\":acc[1]},\n",
    "    \"ptb\":{\"loss\": acc_ptb[0], \"accuracy\":acc_ptb[1]},\n",
    "    \"inv\":{\"loss\": acc_inv[0], \"accuracy\":acc_inv[1]},\n",
    "    \"inv_success_rate\":disagreeing/100}\n",
    "\n",
    "\n",
    "def create_vanilla_model():\n",
    "      print(\"creating vanilla model...\")\n",
    "      \n",
    "      val_images = x_train[:10000]\n",
    "      partial_images = x_train[10000:]\n",
    "      val_labels = y_train[:10000]\n",
    "      partial_labels = y_train[10000:]\n",
    "\n",
    "      model = Sequential()\n",
    "\n",
    "      model.add(Conv2D(32, (5, 5), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "      model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "      model.add(Conv2D(64, (5, 5), activation='relu', kernel_initializer='he_uniform'))\n",
    "      model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "      model.add(Flatten())\n",
    "      model.add(Dense(1024, activation='relu', kernel_initializer='he_uniform'))\n",
    "      model.add(Dense(10, activation='softmax'))\n",
    "     \n",
    "      earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
    "                                        mode =\"min\", patience = 1, \n",
    "                                        restore_best_weights = True)\n",
    "\n",
    "      model.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "      print(\"training vanilla model...\")\n",
    "      history=model.fit(partial_images,to_categorical(partial_labels),\n",
    "                  validation_data =(val_images, to_categorical(val_labels)),\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  shuffle=True,\n",
    "                  verbose=2,\n",
    "                  callbacks =[earlystopping]\n",
    "                  )\n",
    "      print(np.shape(x_test))\n",
    "      acc = model.evaluate(x_test[0:100],to_categorical(y_test[0:100]))\n",
    "      print('BEFORE RETRAIN: Accuracy on clean testing data', acc[1])\n",
    "\n",
    "      return model\n",
    "\n",
    "def create_vanilla_model_tramer(filters=64, s1=5, s2=5, s3=3,\n",
    "               d1=0, d2=0, fc=256,\n",
    "               lr=1e-3, decay=1e-3):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters, kernel_size=(s1, s1),\n",
    "                     activation='relu',\n",
    "                     input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters*2, (s2, s2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters*2, (s3, s3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(d1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(fc, activation='relu'))\n",
    "    model.add(Dropout(d2))\n",
    "    model.add(Dense(10))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='Adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    final = Sequential()\n",
    "    final.add(model)\n",
    "    final.add(Activation('softmax'))\n",
    "    final.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='Adam',\n",
    "                  metrics=['accuracy'])\n",
    "        \n",
    "    final.fit(x_train, to_categorical(y_train, 10),\n",
    "              batch_size=256,\n",
    "              epochs=20,\n",
    "              shuffle=True,\n",
    "              verbose=2,\n",
    "    )\n",
    "    return final    \n",
    "\n",
    "def next_batch(data, labels, data_type):\n",
    "    if data_type==\"mnist\":\n",
    "        global batch_count\n",
    "        start=batch_count*100\n",
    "        end=(batch_count+1)*100\n",
    "        if batch_count<599:\n",
    "            batch_count+=1\n",
    "        else:\n",
    "            batch_count=0\n",
    "        \n",
    "        return data[start:end], labels[start:end]\n",
    "    if data_type==\"inv\":\n",
    "        global batch_count_inv\n",
    "        start=batch_count_inv*100\n",
    "        end=(batch_count_inv+1)*100\n",
    "        if batch_count_inv<4:\n",
    "            batch_count_inv+=1\n",
    "        else:\n",
    "            batch_count_inv=0\n",
    "        \n",
    "        return data[start:end], labels[start:end]\n",
    "\n",
    "\n",
    "# https://github.com/ftramer/Excessive-Invariance\n",
    "def linf_attack(x, nn_adv, eps):\n",
    "    x_adv = x.copy().astype(np.float32)\n",
    "    nn_adv = nn_adv.astype(np.float32)\n",
    "    \n",
    "    # if possible, change the pixels to the target value\n",
    "    idx = np.where((np.abs(nn_adv - x) <= eps*255.) & (x > 0))\n",
    "    x_adv[idx] = nn_adv[idx]\n",
    "    \n",
    "    # otherwise, go as close as possible\n",
    "    idx = np.where(np.abs(nn_adv - x) > eps*255.)\n",
    "    sign = np.sign(nn_adv - x)\n",
    "    x_adv[idx] += sign[idx] * eps * 255.\n",
    "    \n",
    "    x_adv = np.clip(x_adv, x.astype(np.float32) - eps*255, x.astype(np.float32) + eps*255)\n",
    "    x_adv = np.clip(x_adv, 0, 255.)\n",
    "    \n",
    "    return x_adv\n",
    "\n",
    "\n",
    "# https://github.com/ftramer/Excessive-Invariance\n",
    "# tries all rotation-translations of the input and returns the closest neighbor from each class\n",
    "def get_best_neighbors(x, y, all_NNs, grid):\n",
    "    xs = [shift(rotate(x, r, reshape=False), (tx, ty)).reshape(784) for (tx, ty, r) in grid]\n",
    "    xs = np.asarray(xs.copy())\n",
    "    \n",
    "    nns = []\n",
    "    y_nns = []\n",
    "    grids_nn = []\n",
    "    \n",
    "    # find a nearest neighbor in each class\n",
    "    for i in range(10):\n",
    "        if i != y:\n",
    "            X = X_train[Y_train == i]\n",
    "            Y = Y_train[Y_train == i]\n",
    "            distances, indices = all_NNs[i].kneighbors(xs, n_neighbors=1)\n",
    "\n",
    "            best = np.argmin(np.reshape(distances, -1))\n",
    "            best_idx = np.reshape(indices, -1)[best]\n",
    "            nns.append(X[best_idx])\n",
    "            y_nns.append(Y[best_idx])\n",
    "            \n",
    "            # store the inverse rotation+translation to be applied to the target\n",
    "            grids_nn.append(-np.asarray(grid[best]))\n",
    "    \n",
    "    return nns, y_nns, grids_nn\n",
    "\n",
    "\n",
    "# https://github.com/ftramer/Excessive-Invariance\n",
    "def generate_inv_adv_examples(epsilon_to_use, count, save):\n",
    "    import numpy as np\n",
    "    assert epsilon_to_use==0.3 or epsilon_to_use==0.4\n",
    "    \n",
    "    idxs=np.arange(0,count,1,dtype=int)\n",
    "\n",
    "    # Falsely the Invariance-Based Adversarial Examples are generated with the MNIST-Testing data but this doesn't matter because the Adversarial Examples are completely new generated images the Model has never seen.\n",
    "    # So it shouldn't matter if the Adversarial Examples are generated using the Testing-data or the Training-data.\n",
    "    # Saw this just at the end of the work. To fix this, I would have to ask the ten persons again to classify all 500 images and run all experiments again. \n",
    "    # Although the Models are tested only with 100 Examples \n",
    "    assert len(idxs) == count\n",
    "    test_xs = X_test[idxs]\n",
    "    test_ys = Y_test[idxs]\n",
    "\n",
    "    # build a nearest neighbors classifier per class\n",
    "    N = 1\n",
    "    all_NNs = []\n",
    "\n",
    "    for i in range(10):\n",
    "        #Reshape to 1D (28*28=784)\n",
    "        X = X_train[Y_train == i].reshape(-1, 784)\n",
    "        nn = NearestNeighbors(n_neighbors=N)\n",
    "    \n",
    "        nn.fit(X)\n",
    "        all_NNs.append(nn)\n",
    "    # print(all_NNs)\n",
    "\n",
    "\n",
    "\n",
    "    # Rotation-translation parameters\n",
    "    limits = [3, 3, 30]\n",
    "    granularity = [5, 5, 31]\n",
    "    grid = list(product(*list(np.linspace(-l, l, num=g) for l, g in zip(limits, granularity))))\n",
    "\n",
    "\n",
    "\n",
    "    all_nns = []\n",
    "    all_y_nns = []\n",
    "    all_grids_nns = []\n",
    "\n",
    "    # find nearest neighbors for some test inputs (this takes a little while)\n",
    "    for i in range(len(idxs)):\n",
    "        if i % 10 == 0:\n",
    "            print(\"{}/{} done\".format(i, len(idxs)))\n",
    "        x = test_xs[i]\n",
    "        y = test_ys[i]\n",
    "\n",
    "        # find the nearest neighbors for each class, with the corresponding rotation and translation\n",
    "        nns, y_nns, grids_nns = get_best_neighbors(x, y, all_NNs, grid)\n",
    "        nn_advs = [shift(rotate(nn, r, reshape=False), (tx, ty)) for (nn, (tx, ty, r)) in zip(nns, grids_nns)]\n",
    "        all_nns.append(nn_advs)\n",
    "        all_y_nns.append(y_nns)\n",
    "        all_grids_nns.append(np.asarray(grids_nns))\n",
    "\n",
    "    # save everything!\n",
    "    if(save==True):\n",
    "        np.save(\"data/invariance_examples_generation/X_test_{}.npy\".format(count), test_xs)\n",
    "        np.save(\"data/invariance_examples_generation/all_nns.npy\", np.asarray(all_nns))\n",
    "        np.save(\"data/invariance_examples_generation/all_y_nns.npy\", np.asarray(all_y_nns))\n",
    "        np.save(\"data/invariance_examples_generation/all_grids_nns.npy\", np.asarray(all_grids_nns))\n",
    "\n",
    "    all_nns=np.load(\"data/invariance_examples_generation/all_nns.npy\")\n",
    "    all_y_nns=np.load(\"data/invariance_examples_generation/all_y_nns.npy\")\n",
    "    all_grids_nns=np.load(\"data/invariance_examples_generation/all_grids_nns.npy\")\n",
    "    test_xs=np.load(\"data/invariance_examples_generation/X_test_{}.npy\".format(count))\n",
    "\n",
    "  \n",
    "    test_ys = y_test[idxs]\n",
    "\n",
    "    # manually chosen target classes for each source class\n",
    "    targets = {\n",
    "        0: [4, 6, 8, 9],\n",
    "        1: [4, 6, 7, 9],\n",
    "        2: [8],\n",
    "        3: [8],\n",
    "        4: [8, 9],\n",
    "        5: [3, 8],\n",
    "        6: [0],\n",
    "        7: [2, 3],\n",
    "        8: [3],\n",
    "        9: [3, 4, 5]\n",
    "    }\n",
    "\n",
    "    best_y_advs = []\n",
    "    best_targets = []\n",
    "    best_advs = []\n",
    "\n",
    "    for i in range(len(all_nns)):\n",
    "        x = test_xs[i]\n",
    "        y = test_ys[i]\n",
    "    \n",
    "        best_x_adv = None\n",
    "        best_nn_adv = None\n",
    "        amount_removed = []\n",
    "        amount_added = []\n",
    "        rot = []\n",
    "        best_y = None\n",
    "        min_removed = np.inf\n",
    "        for j in range(len(all_nns[i])):\n",
    "            nn_adv = all_nns[i][j]\n",
    "            y_nn = all_y_nns[i][j]\n",
    "            x_adv = linf_attack(x, nn_adv, epsilon_to_use)\n",
    "        \n",
    "            # retain the target that required the least amount of pixels to be \"removed\"\n",
    "            curr_rot = np.abs(all_grids_nns[i][j][-1])\n",
    "            curr_removed = np.sum(np.abs(np.maximum(x/255. - x_adv/255., 0)))\n",
    "            \n",
    "            if y_nn in targets[y] and curr_removed < min_removed:\n",
    "                min_removed = curr_removed\n",
    "                best_y = y_nn\n",
    "                best_x_adv = x_adv\n",
    "                best_nn_adv = (nn_adv, y_nn)\n",
    "                    \n",
    "        best_targets.append(best_nn_adv)\n",
    "        best_advs.append(best_x_adv)\n",
    "        best_y_advs.append(best_y)\n",
    "        \n",
    "\n",
    "    if(save==True):\n",
    "        if epsilon_to_use==0.3:\n",
    "            np.save(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples\", best_advs)\n",
    "            np.save(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples_new_labels\", best_y_advs)\n",
    "        else:\n",
    "            np.save(\"data/invariance_examples/epsilon_0.4/invariance-based_adversarial_examples\", best_advs)\n",
    "            np.save(\"data/invariance_examples/epsilon_0.4/invariance-based_adversarial_examples_new_labels\", best_y_advs)\n",
    " \n",
    "\n",
    "        \n",
    "def ptb_training(ptb_acc_to_achieve, model_to_train, include_inv_training=False, inclusive_training=False, use_iterations=False, iterations=10):\n",
    "    if inclusive_training==True:\n",
    "        include_inv_training=False\n",
    "\n",
    "    inv_advs_to_train=np.load(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples.npy\")\n",
    "    inv_labels_to_train=np.load(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples_human_labels.npy\")\n",
    "    \n",
    "    earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
    "                                        mode =\"min\", patience = 1, \n",
    "                                       restore_best_weights = True)\n",
    "    # while ACCURACY\n",
    "    ptb_acc=0\n",
    "    i=0\n",
    "    y_axis=[]\n",
    "    x_axis_ptb=[]\n",
    "    x_axis_clean=[]\n",
    "    x_axis_inv=[]\n",
    "    if use_iterations==False:    \n",
    "        while ptb_acc<=ptb_acc_to_achieve:\n",
    "            res=test_model(model_to_train)\n",
    "            ptb_acc=res.get(\"ptb\").get(\"accuracy\")\n",
    "            clean_acc=res.get(\"clean\").get(\"accuracy\")\n",
    "            inv_acc=res.get(\"inv\").get(\"accuracy\")\n",
    "\n",
    "            i+=1\n",
    "            y_axis.append(i)\n",
    "            x_axis_ptb.append(ptb_acc)\n",
    "            x_axis_clean.append(clean_acc)\n",
    "            x_axis_inv.append(inv_acc)\n",
    "            fmodel=fb.models.tensorflow.TensorFlowModel(model_to_train, bounds=(0,1))   \n",
    "            x_batch,y_batch=next_batch(x_train,y_train, \"mnist\")\n",
    "            \n",
    "            x_batch_to_train = tf.convert_to_tensor(x_batch, dtype=tf.float32)\n",
    "            y_batch_to_train=tf.convert_to_tensor(y_batch, dtype=tf.int32)\n",
    "\n",
    "            # attack model    \n",
    "            _,advs, success=attack(fmodel, x_batch_to_train, y_batch_to_train, epsilons=epsilon) \n",
    "            success_rate=tf.keras.backend.get_value(success).mean(axis=-1).round(2)\n",
    "\n",
    "\n",
    "\n",
    "            if inclusive_training==True:\n",
    "                x=tf.keras.backend.get_value(advs)\n",
    "                x=x[:,:,:,0]\n",
    "\n",
    "                # perturbation based adversarial examples\n",
    "                x_training=x[0:int(len(x)*0.8)]\n",
    "                x_validation=x[int(len(x)*0.8):int(len(x))]\n",
    "                y_training=y_batch[0:int(len(x)*0.8)]\n",
    "                y_validation=y_batch[int(len(x)*0.8):int(len(x))]\n",
    "\n",
    "                # invariance based adversarial examples\n",
    "                x_inv,y_inv=next_batch(inv_advs_to_train,inv_labels_to_train, \"inv\")\n",
    "                x_inv_training=x_inv[0:int(len(x_inv)*0.8)]\n",
    "                x_inv_validation=x_inv[int(len(x_inv)*0.8):int(len(x_inv))]\n",
    "                y_inv_training=y_inv[0:int(len(y_inv)*0.8)]\n",
    "                y_inv_validation=y_inv[int(len(y_inv)*0.8):int(len(y_inv))]\n",
    "\n",
    "\n",
    "\n",
    "                # combine them into one array\n",
    "                x_training=np.append(x_training,x_inv_training, axis=0)\n",
    "                x_validation=np.append(x_validation,x_inv_validation, axis=0)\n",
    "                y_training=np.append(y_training,y_inv_training)\n",
    "                y_validation=np.append(y_validation,y_inv_validation)\n",
    "             \n",
    "               \n",
    "                \n",
    "                model_to_train.fit(x_training,to_categorical(y_training,num_classes=10),\n",
    "                    validation_data =(x_validation,to_categorical(y_validation, num_classes=10)),\n",
    "                    epochs=epochs,\n",
    "                    verbose=0,\n",
    "                    callbacks =[earlystopping])\n",
    "\n",
    "            else:         \n",
    "                # Retrain model with generated perturbation-based adversarial examples\n",
    "                # 80% Training 20% Validation\n",
    "                x=tf.keras.backend.get_value(advs)\n",
    "                x_training=x[0:int(len(x)*0.8)]\n",
    "                x_validation=x[int(len(x)*0.8):int(len(x))]\n",
    "                y_training=y_batch[0:int(len(x)*0.8)]\n",
    "                y_validation=y_batch[int(len(x)*0.8):int(len(x))]\n",
    "                \n",
    "                model_to_train.fit(x_training,to_categorical(y_training,num_classes=10),\n",
    "                    validation_data =(x_validation,to_categorical(y_validation, num_classes=10)),\n",
    "                    epochs=epochs,\n",
    "                    verbose=0,\n",
    "                    callbacks =[earlystopping]\n",
    "                )\n",
    "\n",
    "                if include_inv_training==True:\n",
    "                    x_training=inv_advs_to_train[0:int(len(inv_advs_to_train)*0.8)]\n",
    "                    x_validation=inv_advs_to_train[int(len(inv_advs_to_train)*0.8):int(len(inv_advs_to_train))]\n",
    "                    y_training=inv_labels_to_train[0:int(len(inv_labels_to_train)*0.8)]\n",
    "                    y_validation=inv_labels_to_train[int(len(inv_labels_to_train)*0.8):int(len(inv_advs_to_train))]\n",
    "                    model_to_train.fit(x_training,to_categorical(y_training,num_classes=10),\n",
    "                        validation_data =(x_validation,to_categorical(y_validation, num_classes=10)),\n",
    "                        epochs=10,\n",
    "                        verbose=0,\n",
    "                        callbacks =[earlystopping]\n",
    "                    )\n",
    "            print(\"i: {} ptb acc: {}, inv_acc: {}\".format(i,ptb_acc, inv_acc))\n",
    "\n",
    "    # while ITERATIONS\n",
    "    else:\n",
    "        while i<iterations:\n",
    "            res=test_model(model_to_train)\n",
    "            ptb_acc=res.get(\"ptb\").get(\"accuracy\")\n",
    "            clean_acc=res.get(\"clean\").get(\"accuracy\")\n",
    "            inv_acc=res.get(\"inv\").get(\"accuracy\")\n",
    "\n",
    "            i+=1\n",
    "            y_axis.append(i)\n",
    "            x_axis_ptb.append(ptb_acc)\n",
    "            x_axis_clean.append(clean_acc)\n",
    "            x_axis_inv.append(inv_acc)\n",
    "            fmodel=fb.models.tensorflow.TensorFlowModel(model_to_train, bounds=(0,1))   \n",
    "            x_batch,y_batch=next_batch(x_train,y_train, \"mnist\")\n",
    "            \n",
    "            x_batch_to_train = tf.convert_to_tensor(x_batch, dtype=tf.float32)\n",
    "            y_batch_to_train=tf.convert_to_tensor(y_batch, dtype=tf.int32)\n",
    "\n",
    "            # attack model    \n",
    "            _,advs, success=attack(fmodel, x_batch_to_train, y_batch_to_train, epsilons=epsilon) \n",
    "            success_rate=tf.keras.backend.get_value(success).mean(axis=-1).round(2)\n",
    "            \n",
    "            if inclusive_training==True:\n",
    "                x=tf.keras.backend.get_value(advs)\n",
    "                x=x[:,:,:,0]\n",
    "\n",
    "                # perturbation based adversarial examples\n",
    "                x_training=x[0:int(len(x)*0.8)]\n",
    "                x_validation=x[int(len(x)*0.8):int(len(x))]\n",
    "                y_training=y_batch[0:int(len(x)*0.8)]\n",
    "                y_validation=y_batch[int(len(x)*0.8):int(len(x))]\n",
    "\n",
    "                # invariance based adversarial examples\n",
    "                x_inv,y_inv=next_batch(inv_advs_to_train,inv_labels_to_train, \"inv\")\n",
    "                x_inv_training=x_inv[0:int(len(x_inv)*0.8)]\n",
    "                x_inv_validation=x_inv[int(len(x_inv)*0.8):int(len(x_inv))]\n",
    "                y_inv_training=y_inv[0:int(len(y_inv)*0.8)]\n",
    "                y_inv_validation=y_inv[int(len(y_inv)*0.8):int(len(y_inv))]\n",
    "\n",
    "\n",
    "\n",
    "                # combine them into one array\n",
    "                x_training=np.append(x_training,x_inv_training, axis=0)\n",
    "                x_validation=np.append(x_validation,x_inv_validation, axis=0)\n",
    "                y_training=np.append(y_training,y_inv_training)\n",
    "                y_validation=np.append(y_validation,y_inv_validation)\n",
    "             \n",
    "               \n",
    "                \n",
    "                model_to_train.fit(x_training,to_categorical(y_training,num_classes=10),\n",
    "                    validation_data =(x_validation,to_categorical(y_validation, num_classes=10)),\n",
    "                    epochs=epochs,\n",
    "                    verbose=0,\n",
    "                    callbacks =[earlystopping]\n",
    "                )\n",
    "\n",
    "            else:         \n",
    "                # Retrain model with generated perturbation-based adversarial examples\n",
    "                # 80% Training 20% Validation\n",
    "                x=tf.keras.backend.get_value(advs)\n",
    "                x_training=x[0:int(len(x)*0.8)]\n",
    "                x_validation=x[int(len(x)*0.8):int(len(x))]\n",
    "                y_training=y_batch[0:int(len(x)*0.8)]\n",
    "                y_validation=y_batch[int(len(x)*0.8):int(len(x))]\n",
    "                \n",
    "                model_to_train.fit(x_training,to_categorical(y_training,num_classes=10),\n",
    "                    validation_data =(x_validation,to_categorical(y_validation, num_classes=10)),\n",
    "                    epochs=epochs,\n",
    "                    verbose=0,\n",
    "                    callbacks =[earlystopping]\n",
    "                )\n",
    "                if include_inv_training==True:\n",
    "                    x_training=inv_advs_to_train[0:int(len(inv_advs_to_train)*0.8)]\n",
    "                    x_validation=inv_advs_to_train[int(len(inv_advs_to_train)*0.8):int(len(inv_advs_to_train))]\n",
    "                    y_training=inv_labels_to_train[0:int(len(inv_labels_to_train)*0.8)]\n",
    "                    y_validation=inv_labels_to_train[int(len(inv_labels_to_train)*0.8):int(len(inv_advs_to_train))]\n",
    "                    model_to_train.fit(x_training,to_categorical(y_training,num_classes=10),\n",
    "                        validation_data =(x_validation,to_categorical(y_validation, num_classes=10)),\n",
    "                        epochs=10,\n",
    "                        verbose=0,\n",
    "                        callbacks =[earlystopping]\n",
    "                    )\n",
    "        \n",
    "            print(\"i: {} ptb acc: {}, inv_acc: {}\".format(i,ptb_acc, inv_acc))\n",
    "    plt.plot( y_axis, x_axis_inv, label = \"INV\")\n",
    "    plt.plot( y_axis, x_axis_clean, label = \"Clean\")\n",
    "    plt.plot( y_axis, x_axis_ptb,label = \"PTB\")\n",
    "    plt.xlabel('Iterationen')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return {\n",
    "        \"model\": model_to_train,\n",
    "        \"clean\":{ \"accuracy\": x_axis_clean},\n",
    "        \"ptb\":{\"accuracy\":x_axis_ptb},\n",
    "        \"inv\":{\"accuracy\":x_axis_inv},\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erstelle/Trainiere das Vanilla Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_vanilla_model().save(\"models/vanilla_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greife Vanilla Modell an und Retrainiere mit Perturbation-Based Adversarial Examples iterativ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Model\n",
    "model=load_model(\"models/vanilla_model\")\n",
    "\n",
    "ptb_acc_to_achieve=0.88\n",
    "model,ptb_acc=ptb_training(ptb_acc_to_achieve, model, use_iterations=True, iterations=100)\n",
    "model.save(\"models/ptb_trained_model_{}_ptb_accuracy\".format(ptb_acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gib PTB Adversarial Training Graph aus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_array(array):\n",
    "    filtered=[]\n",
    "    for i in range(len(array)):\n",
    "        if i%10==0:\n",
    "            filtered.append(array[i])\n",
    "    return filtered\n",
    "\n",
    "\n",
    "y=np.load(\"data/ptb_training/iteration_count_arr.npy\")\n",
    "clean_arr=np.load(\"data/ptb_training/clean_accuracy_arr.npy\")\n",
    "ptb_arr=np.load(\"data/ptb_training/ptb_accuracy_arr.npy\")\n",
    "plt.plot( y, clean_arr, label = \"Clean\")\n",
    "plt.plot( y, ptb_arr,label = \"PTB\")\n",
    "plt.xlabel('Iterationen')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "new_arr_x_ptb=filter_array(ptb_arr)\n",
    "new_arr_x_clean=filter_array(clean_arr)\n",
    "new_arr_y=filter_array(y)\n",
    "\n",
    "\n",
    "plt.plot( new_arr_y, new_arr_x_clean, label = \"Clean\")\n",
    "plt.plot( new_arr_y, new_arr_x_ptb,label = \"PTB\")\n",
    "plt.xlabel('Iterationen')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Max accuracy against PTB: {}\".format(np.max(ptb_arr)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generiere Invariance-Based Adversarial Examples\n",
    "Code ist von https://github.com/ftramer/Excessive-Invariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DON'T UNCOMMENT THIS. this would overwrite the Invariance-Based Adversarial Examples! ---\n",
    "# generate_inv_adv_examples(0.3,500,True)\n",
    "# generate_inv_adv_examples(0.4,500,True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gib Invariance-Based-Based Adversarial Examples aus \n",
    "Diese Beispiele wurden von den zehn Personen angeschaut und die Labels wurden bestimmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_advs_to_train=np.load(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples.npy\")\n",
    "inv_labels_to_train=np.load(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples_new_labels.npy\")\n",
    "x_train\n",
    "\n",
    "print(\"----------EPSILON=0.3----------\")\n",
    "fig, axes = plt.subplots(50,10, figsize=(1.5*10,2*50))\n",
    "for i in range(500):\n",
    "    ax = axes[i//10,i%10]\n",
    "    ax.imshow(inv_advs_to_train[i], cmap='gray')\n",
    "    ax.set_title('Count: {}'.format(i))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "inv_advs_to_train=np.load(\"data/invariance_examples/epsilon_0.4/invariance-based_adversarial_examples.npy\")\n",
    "inv_labels_to_train=np.load(\"data/invariance_examples/epsilon_0.4/invariance-based_adversarial_examples_new_labels.npy\")\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(\"----------EPSILON=0.4----------\")\n",
    "fig, axes = plt.subplots(50,10, figsize=(1.5*10,2*50))\n",
    "for i in range(500):\n",
    "    ax = axes[i//10,i%10]\n",
    "    ax.imshow(inv_advs_to_train[i], cmap='gray')\n",
    "    ax.set_title('Count: {}'.format(i))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erster Durchlauf\n",
    "Anzahl an Invariance-Based Adversarial Examples beim Trainieren variiert. Immer die neuen Labels verwenden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epsilon\n",
    "epsilon=0.3\n",
    "\n",
    "c=[]\n",
    "i=500\n",
    "j=5\n",
    "while j<=i:\n",
    "    c.append(j)\n",
    "    j+=5\n",
    "\n",
    "vanilla_model=load_model(\"models/vanilla_model\")\n",
    "\n",
    "# m=l_infinity_PGD\n",
    "# a=88.9\n",
    "ptb_trained_model=load_model(\"models/ptb_trained_model_0.889_ptb_accuracy_PGD\")\n",
    "\n",
    "# invariance-Based Adversarial Examples to train, use ONLY THE NEW LABELS\n",
    "inv_advs_to_train=np.load(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples.npy\")\n",
    "inv_labels_to_train=np.load(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples_new_labels.npy\")\n",
    "\n",
    "\n",
    "\n",
    "# initialize writing results to csv\n",
    "handler_inv_trained = open('data/results/erster_durchlauf/inv_trained.csv', 'w',encoding='UTF8',newline='')\n",
    "writer_inv_trained = csv.writer(handler_inv_trained)\n",
    "writer_inv_trained.writerow([\"c\",\"clean_acc\",\"ptb_acc\", \"inv_acc\", \"clean_loss\", \"ptb_loss\", \"inv_loss\", \"inv_success_rate\" ])\n",
    "\n",
    "\n",
    "handler_ptb_inv_trained = open('data/results/erster_durchlauf/ptb_inv_trained.csv', 'w',encoding='UTF8',newline='')\n",
    "writer_ptb_inv_trained = csv.writer(handler_ptb_inv_trained)\n",
    "writer_ptb_inv_trained.writerow([\"c\",\"clean_acc\",\"ptb_acc\", \"inv_acc\", \"clean_loss\", \"ptb_loss\", \"inv_loss\", \"inv_success_rate\" ])\n",
    "\n",
    "\n",
    "initial_results_vanilla=test_model(vanilla_model)\n",
    "initial_results_ptb=test_model(ptb_trained_model)\n",
    "\n",
    "data=[0,initial_results_vanilla.get(\"clean\").get(\"accuracy\"),\n",
    "    initial_results_vanilla.get(\"ptb\").get(\"accuracy\"),\n",
    "    initial_results_vanilla.get(\"inv\").get(\"accuracy\"),\n",
    "    initial_results_vanilla.get(\"clean\").get(\"loss\"),\n",
    "    initial_results_vanilla.get(\"ptb\").get(\"loss\"),\n",
    "    initial_results_vanilla.get(\"inv\").get(\"loss\"),\n",
    "    initial_results_vanilla.get(\"inv_success_rate\"),\n",
    "    ]\n",
    "\n",
    "writer_inv_trained.writerow(data)\n",
    "\n",
    "data=[0,initial_results_ptb.get(\"clean\").get(\"accuracy\"),\n",
    "    initial_results_ptb.get(\"ptb\").get(\"accuracy\"),\n",
    "    initial_results_ptb.get(\"inv\").get(\"accuracy\"),\n",
    "    initial_results_ptb.get(\"clean\").get(\"loss\"),\n",
    "    initial_results_ptb.get(\"ptb\").get(\"loss\"),\n",
    "    initial_results_ptb.get(\"inv\").get(\"loss\"),\n",
    "    initial_results_ptb.get(\"inv_success_rate\"),\n",
    "    ]\n",
    "\n",
    "writer_ptb_inv_trained.writerow(data)\n",
    "\n",
    "\n",
    "print(\"Initial results from Vanilla Model: {}\".format(initial_results_vanilla))\n",
    "print(\"Initial results from PTB-Trained Model: {}\".format(initial_results_ptb))\n",
    "\n",
    "\n",
    "results_inv_trained=[]\n",
    "results_ptb_inv_trained=[]\n",
    "for i in range(len(c)):\n",
    "    print(\"Training with {} examples...\".format(c[i]))\n",
    "\n",
    "    vanilla_model.fit(inv_advs_to_train[0:c[i]],to_categorical(inv_labels_to_train[0:c[i]],num_classes=10),\n",
    "    epochs=10,\n",
    "    verbose=0)\n",
    "    \n",
    "\n",
    "    res=test_model(vanilla_model)\n",
    "    results_inv_trained.append(res)\n",
    "    data=[c[i],res.get(\"clean\").get(\"accuracy\"),\n",
    "    res.get(\"ptb\").get(\"accuracy\"),\n",
    "    res.get(\"inv\").get(\"accuracy\"),\n",
    "    res.get(\"clean\").get(\"loss\"),\n",
    "    res.get(\"ptb\").get(\"loss\"),\n",
    "    res.get(\"inv\").get(\"loss\"),\n",
    "    res.get(\"inv_success_rate\"),\n",
    "    ]\n",
    "    # write to csv file\n",
    "    writer_inv_trained.writerow(data)\n",
    "\n",
    "    ptb_trained_model.fit(inv_advs_to_train[0:c[i]],to_categorical(inv_labels_to_train[0:c[i]],num_classes=10),\n",
    "    epochs=10,\n",
    "    verbose=0)\n",
    "\n",
    "    res=test_model(ptb_trained_model)\n",
    "    results_ptb_inv_trained.append(res)\n",
    "    data=[c[i],res.get(\"clean\").get(\"accuracy\"),\n",
    "    res.get(\"ptb\").get(\"accuracy\"),\n",
    "    res.get(\"inv\").get(\"accuracy\"),\n",
    "    res.get(\"clean\").get(\"loss\"),\n",
    "    res.get(\"ptb\").get(\"loss\"),\n",
    "    res.get(\"inv\").get(\"loss\"),\n",
    "    res.get(\"inv_success_rate\"),\n",
    "    ]\n",
    "\n",
    "    # write to csv file\n",
    "    writer_ptb_inv_trained.writerow(data)\n",
    "\n",
    "    # reload models...\n",
    "    vanilla_model=load_model(\"models/vanilla_model\")\n",
    "    ptb_trained_model=load_model(\"models/ptb_trained_model_0.889_ptb_accuracy_PGD\")\n",
    "handler_ptb_inv_trained.close()\n",
    "handler_inv_trained.close()\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"----------Results INV-Trained Model----------\")\n",
    "i=0\n",
    "for entry in results_inv_trained:\n",
    "    print(\"Clean accuracy INV_trained with {} examples: {}\".format(c[i],entry.get(\"clean\").get(\"accuracy\")))\n",
    "    i+=1\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"----------Results PTB-INV-Trained Model----------\")\n",
    "i=0\n",
    "for entry in results_ptb_inv_trained:\n",
    "    print(\"Clean accuracy PTB-INV_trained with {} examples: {}\".format(c[i],entry.get(\"clean\").get(\"accuracy\")))\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zweiter Durchlauf \n",
    "Dasselbe wie beim ersten Durchlauf mit dem Unterschied, dass die Labels beim Retrainieren mit Invariance-Based Adversarial Examples von zehn Personen bestimmt wurden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epsilon\n",
    "epsilon=0.3\n",
    "\n",
    "# c\n",
    "c=[]\n",
    "i=500\n",
    "j=5\n",
    "while j<=i:\n",
    "    c.append(j)\n",
    "    j+=5\n",
    "\n",
    "\n",
    "vanilla_model=load_model(\"models/vanilla_model\")\n",
    "\n",
    "# m=l_infinity_PGD\n",
    "# a=88.9\n",
    "ptb_trained_model=load_model(\"models/ptb_trained_model_0.889_ptb_accuracy_PGD\")\n",
    "\n",
    "# Invariance-Based Adversarial Examples to train, use ONLY THE NEW LABELS\n",
    "inv_advs_to_train=np.load(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples.npy\")\n",
    "inv_labels_to_train=np.load(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples_human_labels.npy\")\n",
    "\n",
    "print(np.shape(inv_labels_to_train))\n",
    "\n",
    "# Initialize writing results to csv\n",
    "handler_inv_trained = open('data/results/zweiter_durchlauf/inv_trained.csv', 'w',encoding='UTF8',newline='')\n",
    "writer_inv_trained = csv.writer(handler_inv_trained)\n",
    "writer_inv_trained.writerow([\"c\",\"clean_acc\",\"ptb_acc\", \"inv_acc\", \"clean_loss\", \"ptb_loss\", \"inv_loss\", \"inv_success_rate\" ])\n",
    "\n",
    "\n",
    "handler_ptb_inv_trained = open('data/results/zweiter_durchlauf/ptb_inv_trained.csv', 'w',encoding='UTF8',newline='')\n",
    "writer_ptb_inv_trained = csv.writer(handler_ptb_inv_trained)\n",
    "writer_ptb_inv_trained.writerow([\"c\",\"clean_acc\",\"ptb_acc\", \"inv_acc\", \"clean_loss\", \"ptb_loss\", \"inv_loss\", \"inv_success_rate\" ])\n",
    "\n",
    "initial_results_vanilla=test_model(vanilla_model)\n",
    "initial_results_ptb=test_model(ptb_trained_model)\n",
    "\n",
    "data=[0,initial_results_vanilla.get(\"clean\").get(\"accuracy\"),\n",
    "    initial_results_vanilla.get(\"ptb\").get(\"accuracy\"),\n",
    "    initial_results_vanilla.get(\"inv\").get(\"accuracy\"),\n",
    "    initial_results_vanilla.get(\"clean\").get(\"loss\"),\n",
    "    initial_results_vanilla.get(\"ptb\").get(\"loss\"),\n",
    "    initial_results_vanilla.get(\"inv\").get(\"loss\"),\n",
    "    initial_results_vanilla.get(\"inv_success_rate\"),\n",
    "    ]\n",
    "\n",
    "writer_inv_trained.writerow(data)\n",
    "\n",
    "data=[0,initial_results_ptb.get(\"clean\").get(\"accuracy\"),\n",
    "    initial_results_ptb.get(\"ptb\").get(\"accuracy\"),\n",
    "    initial_results_ptb.get(\"inv\").get(\"accuracy\"),\n",
    "    initial_results_ptb.get(\"clean\").get(\"loss\"),\n",
    "    initial_results_ptb.get(\"ptb\").get(\"loss\"),\n",
    "    initial_results_ptb.get(\"inv\").get(\"loss\"),\n",
    "    initial_results_ptb.get(\"inv_success_rate\"),\n",
    "    ]\n",
    "\n",
    "writer_ptb_inv_trained.writerow(data)\n",
    "\n",
    "print(\"Initial results from Vanilla Model: {}\".format(initial_results_vanilla))\n",
    "print(\"Initial results from PTB-Trained Model: {}\".format(initial_results_ptb))\n",
    "\n",
    "\n",
    "results_inv_trained=[]\n",
    "results_ptb_inv_trained=[]\n",
    "for i in range(len(c)):\n",
    "    print(\"Training with {} examples...\".format(c[i]))\n",
    "\n",
    "    vanilla_model.fit(inv_advs_to_train[0:c[i]],to_categorical(inv_labels_to_train[0:c[i]],num_classes=10),\n",
    "    epochs=10,\n",
    "    verbose=0)\n",
    "    \n",
    "    res=test_model(vanilla_model)\n",
    "    results_inv_trained.append(res)\n",
    "    data=[c[i],res.get(\"clean\").get(\"accuracy\"),\n",
    "    res.get(\"ptb\").get(\"accuracy\"),\n",
    "    res.get(\"inv\").get(\"accuracy\"),\n",
    "    res.get(\"clean\").get(\"loss\"),\n",
    "    res.get(\"ptb\").get(\"loss\"),\n",
    "    res.get(\"inv\").get(\"loss\"),\n",
    "    res.get(\"inv_success_rate\"),\n",
    "    ]\n",
    "    # write to csv file\n",
    "    writer_inv_trained.writerow(data)\n",
    "\n",
    "    ptb_trained_model.fit(inv_advs_to_train[0:c[i]],to_categorical(inv_labels_to_train[0:c[i]],num_classes=10),\n",
    "    epochs=10,\n",
    "    verbose=0)\n",
    "\n",
    "    res=test_model(ptb_trained_model)\n",
    "    results_ptb_inv_trained.append(res)\n",
    "    data=[c[i],res.get(\"clean\").get(\"accuracy\"),\n",
    "    res.get(\"ptb\").get(\"accuracy\"),\n",
    "    res.get(\"inv\").get(\"accuracy\"),\n",
    "    res.get(\"clean\").get(\"loss\"),\n",
    "    res.get(\"ptb\").get(\"loss\"),\n",
    "    res.get(\"inv\").get(\"loss\"),\n",
    "    res.get(\"inv_success_rate\"),\n",
    "    ]\n",
    "\n",
    "    # write to csv file\n",
    "    writer_ptb_inv_trained.writerow(data)\n",
    "\n",
    "    # reload models...\n",
    "    vanilla_model=load_model(\"models/vanilla_model\")\n",
    "    ptb_trained_model=load_model(\"models/ptb_trained_model_0.889_ptb_accuracy_PGD\")\n",
    "\n",
    "handler_ptb_inv_trained.close()\n",
    "handler_inv_trained.close()\n",
    "\n",
    "print()\n",
    "print(\"----------Results INV-Trained Model----------\")\n",
    "i=0\n",
    "for entry in results_inv_trained:\n",
    "    print(\"Clean accuracy INV_trained with {} examples: {}\".format(c[i],entry.get(\"clean\").get(\"accuracy\")))\n",
    "    i+=1\n",
    "\n",
    "print()\n",
    "print(\"----------Results PTB-INV-Trained Model----------\")\n",
    "i=0\n",
    "for entry in results_ptb_inv_trained:\n",
    "    print(\"Clean accuracy PTB-INV_trained with {} examples: {}\".format(c[i],entry.get(\"clean\").get(\"accuracy\")))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dritter Durchlauf\n",
    "PTB-INV Trained/INV-PTB Trained/simultan/inklusiv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epsilon\n",
    "epsilon=0.3\n",
    "iterations=1500\n",
    "ptb_acc_to_achieve=1\n",
    "\n",
    "# invariance-Based Adversarial Examples to train, use ONLY THE NEW LABELS\n",
    "inv_advs_to_train=np.load(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples.npy\")\n",
    "inv_labels_to_train=np.load(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples_human_labels.npy\")\n",
    "\n",
    "\n",
    "\n",
    "# handler and writer...\n",
    "handler_simultan_trained = open('data/results/dritter_durchlauf/simultan.csv', 'w',encoding='UTF8',newline='')\n",
    "writer_simultan_trained = csv.writer(handler_simultan_trained)\n",
    "writer_simultan_trained.writerow([\"i\",\"clean_acc\",\"ptb_acc\", \"inv_acc\"])\n",
    "\n",
    "handler_inclusive_trained = open('data/results/dritter_durchlauf/inclusive.csv', 'w',encoding='UTF8',newline='')\n",
    "writer_inclusive_trained = csv.writer(handler_inclusive_trained)\n",
    "writer_inclusive_trained.writerow([\"i\",\"clean_acc\",\"ptb_acc\", \"inv_acc\"])\n",
    "\n",
    "handler_inv_ptb_trained = open('data/results/dritter_durchlauf/inv_ptb.csv', 'w',encoding='UTF8',newline='')\n",
    "writer_inv_ptb_trained = csv.writer(handler_inv_ptb_trained)\n",
    "writer_inv_ptb_trained.writerow([\"i\",\"clean_acc\",\"ptb_acc\", \"inv_acc\", ])\n",
    "\n",
    "handler_ptb_inv_trained = open('data/results/dritter_durchlauf/ptb_inv.csv', 'w',encoding='UTF8',newline='')\n",
    "writer_ptb_inv_trained = csv.writer(handler_ptb_inv_trained)\n",
    "writer_ptb_inv_trained.writerow([\"i\",\"clean_acc\",\"ptb_acc\", \"inv_acc\", ])\n",
    "\n",
    "# inclusive training\n",
    "vanilla_model=load_model(\"models/vanilla_model\")\n",
    "res=ptb_training(ptb_acc_to_achieve, vanilla_model, include_inv_training=False, inclusive_training=True, use_iterations=True, iterations=iterations)\n",
    "\n",
    "ptb_acc_arr_inclusive=res.get(\"ptb\").get(\"accuracy\")\n",
    "inv_acc_arr_inclusive=res.get(\"inv\").get(\"accuracy\")\n",
    "clean_acc_arr_inclusive=res.get(\"clean\").get(\"accuracy\")\n",
    "\n",
    "for i in range(iterations):\n",
    "     data=[i,clean_acc_arr_inclusive[i],ptb_acc_arr_inclusive[i],inv_acc_arr_inclusive[i]]\n",
    "     writer_inclusive_trained.writerow(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# simultan training\n",
    "vanilla_model=load_model(\"models/vanilla_model\")\n",
    "res=ptb_training(ptb_acc_to_achieve, vanilla_model, include_inv_training=True, use_iterations=True, iterations=iterations)\n",
    "\n",
    "ptb_acc_arr_simultan=res.get(\"ptb\").get(\"accuracy\")\n",
    "inv_acc_arr_simultan=res.get(\"inv\").get(\"accuracy\")\n",
    "clean_acc_arr_simultan=res.get(\"clean\").get(\"accuracy\")\n",
    "\n",
    "\n",
    "for i in range(iterations):\n",
    "    data=[i,clean_acc_arr_simultan[i],ptb_acc_arr_simultan[i],inv_acc_arr_simultan[i]]\n",
    "    writer_simultan_trained.writerow(data)\n",
    "\n",
    "vanilla_model=load_model(\"models/vanilla_model\")\n",
    "\n",
    "\n",
    "\n",
    "# first INV-Training...\n",
    "print(\"INV-Training\")\n",
    "vanilla_model.fit(inv_advs_to_train,to_categorical(inv_labels_to_train,num_classes=10),\n",
    "epochs=10,\n",
    "verbose=0)\n",
    "\n",
    "result=test_model(vanilla_model)\n",
    "\n",
    "data=[iterations+1,result.get(\"clean\").get(\"accuracy\"),result.get(\"ptb\").get(\"accuracy\"),result.get(\"inv\").get(\"accuracy\")]\n",
    "writer_inv_ptb_trained.writerow(data)\n",
    "\n",
    "\n",
    "\n",
    "# then PTB-Training\n",
    "res=ptb_training(ptb_acc_to_achieve, vanilla_model,use_iterations=True, iterations=iterations)\n",
    "\n",
    "\n",
    "ptb_acc_arr_inv_ptb=res.get(\"ptb\").get(\"accuracy\")\n",
    "inv_acc_arr_inv_ptb=res.get(\"inv\").get(\"accuracy\")\n",
    "clean_acc_arr_inv_ptb=res.get(\"clean\").get(\"accuracy\")\n",
    "\n",
    "for i in range(iterations):\n",
    "    data=[i,clean_acc_arr_inv_ptb[i],ptb_acc_arr_inv_ptb[i],inv_acc_arr_inv_ptb[i]]\n",
    "    writer_inv_ptb_trained.writerow(data)\n",
    "\n",
    "vanilla_model=load_model(\"models/vanilla_model\")\n",
    "\n",
    "\n",
    "\n",
    "# first PTB-Training\n",
    "res=ptb_training(ptb_acc_to_achieve, vanilla_model,use_iterations=True, iterations=iterations)\n",
    "\n",
    "ptb_acc_arr_ptb_inv=res.get(\"ptb\").get(\"accuracy\")\n",
    "inv_acc_arr_ptb_inv=res.get(\"inv\").get(\"accuracy\")\n",
    "clean_acc_arr_ptb_inv=res.get(\"clean\").get(\"accuracy\")\n",
    "\n",
    "\n",
    "for i in range(iterations):\n",
    "    data=[i,clean_acc_arr_ptb_inv[i],ptb_acc_arr_ptb_inv[i],inv_acc_arr_ptb_inv[i]]\n",
    "    writer_ptb_inv_trained.writerow(data)\n",
    "\n",
    "# then INV-Training\n",
    "print(\"INV-Training\")\n",
    "vanilla_model.fit(inv_advs_to_train,to_categorical(inv_labels_to_train,num_classes=10),\n",
    "    epochs=10,\n",
    "    verbose=0)\n",
    "\n",
    "result=test_model(vanilla_model)\n",
    "\n",
    "data=[iterations+1,result.get(\"clean\").get(\"accuracy\"),result.get(\"ptb\").get(\"accuracy\"),result.get(\"inv\").get(\"accuracy\")]\n",
    "writer_ptb_inv_trained.writerow(data)\n",
    "\n",
    "\n",
    "handler_ptb_inv_trained.close()\n",
    "handler_simultan_trained.close()\n",
    "handler_inv_ptb_trained.close()\n",
    "handler_inclusive_trained.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
